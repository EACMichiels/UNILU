{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Kernels\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<span style=\"color: red; font-weight: bold;\">\n",
    "Please replace the \"?\"-signs by real code\n",
    "</span>\n",
    "<br>\n",
    "In this tutorial we will apply a Quantum Kernel Method to calculate a single kernel matrix entry for data with many features, using a real quantum computer. We will not estimate an entire kernel matrix for a large dataset, in order to respect time on IBM quantum computers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have not already, install scikit learn\n",
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import unitary_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling to more features and qubits\n",
    "\n",
    "In this section, we will repeat the calculation of a single matrix element, but for a much larger number of features, sketching the path to scale toward utility. The restriction to a single matrix element is done so that the process can be shown without using up too much of your allotted time on quantum computers.\n",
    "\n",
    "### Step 1: Map classical inputs to a quantum problem\n",
    "\n",
    "We will assume a starting point of a dataset in which each data point has 42 features. As in the first example, we will calculate a single kernel matrix element, requiring two data points. \n",
    "\n",
    "\n",
    "<span style=\"color: blue; font-weight: bold;\">\n",
    "The two points below have 42 features and a single category variable ($\\pm 1$).\n",
    "</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two mock data points, including category labels, as in training\n",
    "\n",
    "large_data = [\n",
    "    [\n",
    "        -0.028,\n",
    "        -1.49,\n",
    "        -1.698,\n",
    "        0.107,\n",
    "        -1.536,\n",
    "        -1.538,\n",
    "        -1.356,\n",
    "        -1.514,\n",
    "        -0.109,\n",
    "        -1.8,\n",
    "        -0.122,\n",
    "        -1.651,\n",
    "        -1.955,\n",
    "        -0.123,\n",
    "        -1.732,\n",
    "        0.091,\n",
    "        -0.048,\n",
    "        -0.128,\n",
    "        -0.026,\n",
    "        0.082,\n",
    "        -1.263,\n",
    "        0.065,\n",
    "        0.004,\n",
    "        -0.055,\n",
    "        -0.08,\n",
    "        -0.173,\n",
    "        -1.734,\n",
    "        -0.39,\n",
    "        -1.451,\n",
    "        0.078,\n",
    "        -1.578,\n",
    "        -0.025,\n",
    "        -0.184,\n",
    "        -0.119,\n",
    "        -1.336,\n",
    "        0.055,\n",
    "        -0.204,\n",
    "        -1.578,\n",
    "        0.132,\n",
    "        -0.121,\n",
    "        -1.599,\n",
    "        -0.187,\n",
    "        -1,\n",
    "    ],\n",
    "    [\n",
    "        -1.414,\n",
    "        -1.439,\n",
    "        -1.606,\n",
    "        0.246,\n",
    "        -1.673,\n",
    "        0.002,\n",
    "        -1.317,\n",
    "        -1.262,\n",
    "        -0.178,\n",
    "        -1.814,\n",
    "        0.013,\n",
    "        -1.619,\n",
    "        -1.86,\n",
    "        -0.25,\n",
    "        -0.212,\n",
    "        -0.214,\n",
    "        -0.033,\n",
    "        0.071,\n",
    "        -0.11,\n",
    "        -1.607,\n",
    "        0.441,\n",
    "        -0.143,\n",
    "        -0.009,\n",
    "        -1.655,\n",
    "        -1.579,\n",
    "        0.381,\n",
    "        -1.86,\n",
    "        -0.079,\n",
    "        -0.088,\n",
    "        -0.058,\n",
    "        -1.481,\n",
    "        -0.064,\n",
    "        -0.065,\n",
    "        -1.507,\n",
    "        0.177,\n",
    "        -0.131,\n",
    "        -0.153,\n",
    "        0.07,\n",
    "        -1.627,\n",
    "        0.593,\n",
    "        -1.547,\n",
    "        -0.16,\n",
    "        -1,\n",
    "    ],\n",
    "]\n",
    "train_data = [large_data[0][:-1], large_data[1][:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the `zz_feature_map` produced rather deep circuits in the case of relatively few features (14 features). As we increase the number of features, we need to closely monitor circuit depth. To illustrate this, we will first try using the `zz_feature_map` and check the depth of the resulting circuit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import zz_feature_map\n",
    "\n",
    "fm = ?(\n",
    "    feature_dimension=np.shape(train_data)[1], entanglement=\"linear\", reps=1\n",
    ")\n",
    "\n",
    "unitary1 = ?.assign_parameters(train_data[0])\n",
    "unitary2 = ?.assign_parameters(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import unitary_overlap\n",
    "\n",
    "\n",
    "overlap_circ = unitary_overlap(?, ?)\n",
    "overlap_circ.measure_all()\n",
    "\n",
    "print(\"circuit depth = \", overlap_circ.decompose(reps=2).depth())\n",
    "print(\n",
    "    \"two-qubit depth\",\n",
    "    overlap_circ.decompose().depth(lambda instr: len(instr.qubits) > 1),\n",
    ")\n",
    "# overlap_circ.draw(\"mpl\", scale=0.6, style=\"iqp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described before, determining exactly how deep is too deep is nuanced. But a two-qubit depth of more than 100, even before transpilation is a non-starter. \n",
    "\n",
    "<span style=\"color: blue; font-weight: bold;\">\n",
    "This is why custom feature maps have been emphasized throughout this lesson. If you know something about the structure of your entire dataset, you should design an entanglement map with that structure in mind. \n",
    "</span>\n",
    "    \n",
    "Here, since we are only calculating the inner product between two such data points, we have prioritized low circuit depth over any detailed consideration of data structure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import Parameter, ParameterVector, QuantumCircuit\n",
    "\n",
    "# Prepare feature map for computing overlap\n",
    "\n",
    "entangler_map = [\n",
    "    [3, 4],\n",
    "    [2, 5],\n",
    "    [1, 4],\n",
    "    [2, 3],\n",
    "    [4, 6],\n",
    "    [7, 9],\n",
    "    [10, 11],\n",
    "    [9, 12],\n",
    "    [8, 11],\n",
    "    [9, 10],\n",
    "    [11, 13],\n",
    "    [14, 16],\n",
    "    [17, 18],\n",
    "    [16, 19],\n",
    "    [15, 18],\n",
    "    [16, 17],\n",
    "    [18, 20],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the entangler map above to build a feature map\n",
    "\n",
    "num_features = np.shape(train_data)[1]\n",
    "num_qubits = int(num_features / 2)\n",
    "\n",
    "fm = QuantumCircuit(num_qubits)\n",
    "training_param = Parameter(\"Î¸\")\n",
    "feature_params = ParameterVector(\"x\", num_qubits * 2)\n",
    "fm.ry(training_param, fm.qubits)\n",
    "for cz in ?:\n",
    "    fm.cz(cz[0], cz[1])\n",
    "for i in range(?):\n",
    "    fm.rz(-2 * feature_params[2 * i + 1], i)\n",
    "    fm.rx(-2 * feature_params[2 * i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import unitary_overlap\n",
    "\n",
    "# Assign features of each data point to a unitary, an instance of the general feature map.\n",
    "\n",
    "unitary1 = fm.assign_parameters(list(train_data[0]) + [np.pi / 2])\n",
    "unitary2 = fm.assign_parameters(list(train_data[1]) + [np.pi / 2])\n",
    "\n",
    "# Create the overlap circuit\n",
    "\n",
    "overlap_circ = unitary_overlap(?, ?)\n",
    "?.measure_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't bother checking the depths yet, since what really matters is the transpiled two-qubit depth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Optimize problem for quantum execution\n",
    "\n",
    "We start by selecting the least busy backend, then optimize our circuit for running on that backend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "# Get the least busy backend\n",
    "service = ?()\n",
    "backend = ?.least_busy(\n",
    "    operational=True, simulator=False, min_num_qubits=fm.num_qubits\n",
    ")\n",
    "print(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On small-scale jobs, a preset pass manager will often return the same circuit with the same depth, reliably. But in very large, complex circuits the pass manager can return different transpiled circuits each time it runs. This is because it is using heuristics, and because very large circuits will have a complicated landscape of possible optimizations. It is often useful to transpile a few times and take the shallowest circuit. This only introduces classical overhead and may substantially improve the results from the quantum computer.\n",
    "\n",
    "Here, we transpile the unitary overlap circuit 20 times, and look at the depths of the circuits obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply level 3 optimization to our overlap circuit\n",
    "transpiled_qcs = []\n",
    "transpiled_depths = []\n",
    "transpiled_twoqubit_depths = []\n",
    "for i in range(1, ?):\n",
    "    pm = generate_preset_pass_manager(optimization_level=3, backend=backend)\n",
    "    overlap_ibm = pm.run(overlap_circ)\n",
    "    transpiled_qcs.append(?)\n",
    "    transpiled_depths.append(?.decompose().depth())\n",
    "    transpiled_twoqubit_depths.append(\n",
    "        overlap_ibm.decompose().depth(lambda instr: len(instr.qubits) > 1)\n",
    "    )\n",
    "\n",
    "print(\"circuit depth = \", overlap_ibm.decompose().depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transpiled_depths)\n",
    "print(transpiled_twoqubit_depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there variation in the total gate depth with different transpilation passes?\n",
    "<br>\n",
    "We will use the `transpiled_qcs[1]`.\n",
    "<br>\n",
    "What is the depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_ibm = transpiled_qcs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Execute using Qiskit Runtime Primitives\n",
    "\n",
    "As we scale closer to utility, simulators will not be useful. Only the syntax for real quantum computers is shown here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-weight: bold;\">\n",
    "We apply Dynamical Decoupling and Twirling.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import runtime primitive\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "\n",
    "# Define backend directly (instead of Session)\n",
    "# For example, using the IBM provider:\n",
    "# backend = provider.get_backend(\"ibmq_qasm_simulator\")\n",
    "# or any other backend you have access to\n",
    "num_shots = 10000\n",
    "\n",
    "# Create the sampler directly with backend\n",
    "sampler = Sampler(mode=backend)\n",
    "\n",
    "# Access options (if supported by your backend/plan)\n",
    "options = sampler.options\n",
    "?.dynamical_decoupling.enable = True\n",
    "?.twirling.enable_gates = True\n",
    "\n",
    "# Run and get counts\n",
    "result = sampler.run([?], shots=?).result()\n",
    "counts = ?[0].data.meas.get_int_counts()\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Post-process, return result in classical format\n",
    "\n",
    "As described in the introduction, the most useful measurement here is the probability of measuring the zero state $|00000\\rangle$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.get(0, 0.0) / ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process for the single kernel matrix element could be repeated between other data pairs in your set to obtain the full kernel matrix. The dimension of the kernel matrix is dictated by the number of points in your training data, not the number of features. So the computing cost of manipulating the kernel matrix into a predictive model does not scale like the number of features or qubits. Even for relatively small datasets with large numbers of features, the data would still need to be matched to a feature map that yields effective classification.\n",
    "\n",
    "### Scaling and future work\n",
    "\n",
    "The kernel method requires that we measure the $|0\\rangle$ as accurately as possible. But gate errors and readout errors mean that there is some non-zero probability $p$ that any given qubit will be erroneously measured to be in the $|1\\rangle$ state. Even with the oversimplification that the probability of $|0\\rangle$ should be $100\\%$, for many features encoded on, say, $N$ bits, the probability of correctly measuring all bits to be $|0\\rangle$ is reduced to $(1-p)^N$. As $N$ becomes large, this method becomes less and less reliable. Overcoming this difficulty and scaling kernel estimation to more and more features is an area of current research. To learn more about this issue, see this work by [Thanasilp, Wang, Cerezo, and Holmes.](https://www.nature.com/articles/s41467-024-49287-w) We recommend you explore what can be done with current quantum computers, and also look forward to what will be possible in the era of error correction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "\n",
    "Calculating a quantum kernel involves\n",
    "\n",
    "*   calculating kernel matrix entries, using pairs of training data points\n",
    "*   encoding the data and mapping it via a feature mapping\n",
    "*   optimizing your circuit for running on real quantum computers / backends\n",
    "\n",
    "The quantum kernel can then be used in classical machine learning algorithms, as in this notebook.\n",
    "\n",
    "<span style=\"color: blue; font-weight: bold;\">    \n",
    "Some key things to keep in mind when using quantum kernels include:\n",
    "</span>\n",
    "\n",
    "*   Is the dataset likely to benefit from quantum kernel methods?\n",
    "*   Try different feature maps and entanglement schemes.\n",
    "*   Is the circuit depth acceptable?\n",
    "*   Try running a pass manager multiple times and use the smallest-depth circuit you can get.\n",
    "\n",
    "Quantum kernel methods are potentially powerful tools given a proper match between datasets with quantum-amenable features, and a suitable quantum feature map. To better understand where quantum kernels are likely to be useful, we recommend reading [Liu, Arunachalam & Temme (2021)](https://www.nature.com/articles/s41567-021-01287-z).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "description": "Quantum kernels are used initially to determine a kernel matrix element, a full kernel matrix and the interface with classical kernel tools is presented.",
  "kernelspec": {
   "display_name": "Python 3 [Default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "title": "Quantum kernel methods"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
